{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (60000, 28, 28)\n",
      "Training Data Labels Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Labels Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x688dccb38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot the first image from the dataset\n",
    "plt.imshow(X_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Our image is an array of pixels ranging from 0 to 255\n",
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (60000, 784)\n",
      "Testing Shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    " # We want to flatten our image of 28x28 pixels to a 1D array of 784 pixels\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNG\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Next, we normalize our training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 9\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "# Original label of `5` is one-hot encoded as `0000010000`\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JUNG\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(50, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # We can summarize our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JUNG\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.5282 - acc: 0.8175\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.4002 - acc: 0.8592\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.3579 - acc: 0.8706\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.3352 - acc: 0.8783\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.3167 - acc: 0.8841\n",
      "Epoch 6/10\n"
     ]
    }
   ],
   "source": [
    " # Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save the model\n",
    "model.save(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction. The result should be 0000010000000 for a 5\n",
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[2], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction. The resulting class should match the digit\n",
    "print(f\"One-Hot-Encoded Prediction: {model.predict(test).round()}\")\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
